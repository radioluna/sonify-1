{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Listening for Sonification Techniques\n",
    "\n",
    "## \"Thereâ€™s more to listening than meets the ear.\" - composer/teacher Pauline Oliveros \n",
    "\n",
    "Pauline also described Deep Listening as \n",
    "\n",
    "*Listening in every possible way to everything possible to hear no matter what one is doing.* \n",
    "\n",
    "There are many ways of listening but attentive listening is guided and focussed sort of listening ... a deep listening. These modules are designed to help you become a more focused listener for a specific type of aural experience. These lessons are specifically focuse on learning to listen in a special way to engage a new understanding of a new area of information called: Sonification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Sonification?\n",
    "\n",
    "The \"classic\" definition, as found on Wikipedia and other sources is:\n",
    "    \n",
    "`Sonification is the use of non-speech audio to convey information or perceptualize data. Auditory perception has advantages in temporal, spatial, amplitude, and frequency resolution that open possibilities as an alternative or complement to visualization techniques.`\n",
    "This covers many of the ideas associated with the act of data sonification. There are many techniques for sonificaiton and most if not all of them are unfamiliar to many of us. For that reason this set of \"deep listening for sonification technics\" training modules have been designed to help orient the listener to new ways of experiencing audio. The focus will be on understanding the sound itself as a source of information.\n",
    "\n",
    "It is interesting to note, in definition above, the use of the term _non-speech audio_ In these training modules we are starting with what we call _wordification_ which is a familiar way to understand informaiton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a sound\n",
    "import numpy as np\n",
    "framerate = 44100\n",
    "t = np.linspace(0,5,framerate*5)\n",
    "data = np.sin(2*np.pi*220*t) + np.sin(2*np.pi*224*t)\n",
    "# Audio(data,rate=framerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hearing Test\n",
    "\n",
    "Before we get started with really taking our listening to the next level lets take a hearing test. The link that follows will take you to the online hearing test developed by Stephan Pigeon. We are using it with his permission. Please follow the instructions closely, doing the test with both ears and when you have finished make a note of the results. It is your opportunity to identify if you have any gaps in your own hearing response.\n",
    "<blockquote class=\"embedly-card\"><h4><a href=\"https://hearingtest.online/\">Hearing Test & Audiogram Printout * Online & Free</a></h4><p>The most accurate hearing test on the internet * Audiogram printout helps monitor your hearing over time * Independent * Fast * Calibrated * Online * Free</p></blockquote>\n",
    "<script async src=\"//cdn.embedly.com/widgets/platform.js\" charset=\"UTF-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordification - data as speech\n",
    "\n",
    "Here is out first training module where we try out the idea of interacting with data by listening to it _speak_ to us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c51f91bffd41deb5864975f18d1b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "widgets.IntSlider(\n",
    "    value=7,\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='Wordification:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/opt/anaconda3/lib/python36.zip',\n",
       " '/opt/anaconda3/lib/python3.6',\n",
       " '/opt/anaconda3/lib/python3.6/lib-dynload',\n",
       " '/opt/anaconda3/lib/python3.6/site-packages',\n",
       " '/opt/anaconda3/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/home/scotgl/.ipython']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
